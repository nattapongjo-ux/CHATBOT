import streamlit as st
import os
import time
import backend

# =================‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö (Config)=================
try:
    API_KEY = st.secrets["API_KEY"]
    DATA_PATH = st.secrets["DATA_PATH"]
except FileNotFoundError:
    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå secrets.toml ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå .streamlit/secrets.toml ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
    st.stop()
except KeyError as e:
    st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡πà‡∏≤ {e} ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå secrets.toml")
    st.stop()

st.set_page_config(page_title="Agricultural Data AI", page_icon="üåæ", layout="wide")

try:
    backend.setup_api(API_KEY)
except Exception as e:
    st.error(f"‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")

# =================‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà: ‡πÄ‡∏ä‡πá‡∏Ñ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î=================
def get_files_from_province_folder(base_path, user_prompt):
    """
    ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÉ‡∏ô prompt ‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î(‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå) ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà 
    ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ -> ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ list ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ô‡∏±‡πâ‡∏ô
    ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ -> ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ list ‡∏ß‡πà‡∏≤‡∏á
    """
    if not os.path.exists(base_path):
        return [], None

    # 1. ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î)
    all_folders = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]
    
    matched_province = None
    target_files = []

    # 2. ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏´‡∏°
    for folder in all_folders:
        # ‡πÄ‡∏ä‡πá‡∏Ñ‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢: ‡∏ñ‡πâ‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô prompt (‡πÄ‡∏ä‡πà‡∏ô prompt="‡∏Ç‡πâ‡∏≤‡∏ß‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ï‡∏≤‡∏Å", folder="‡∏ï‡∏≤‡∏Å")
        if folder in user_prompt: 
            matched_province = folder
            break
    
    # 3. ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î ‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏ô‡∏±‡πâ‡∏ô
    if matched_province:
        folder_path = os.path.join(base_path, matched_province)
        for root, dirs, files in os.walk(folder_path):
            for file in files:
                # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö
                if file.lower().endswith(('.csv', '.xlsx', '.xls', '.txt', '.pdf', '.docx', '.json')):
                    target_files.append(os.path.join(root, file))
                    
    return target_files, matched_province

# =================‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• (UI)=================
def load_css(file_name):
    with open(file_name, encoding="utf-8") as f:
        st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)

if os.path.exists("style.css"):
    load_css("style.css")

st.markdown('<div class="main-title">üåæ ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏©‡∏ï‡∏£ 17 ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-title">AI Powered Data Analysis | Gemini 2.5 Flash Lite</div>', unsafe_allow_html=True)

if not os.path.exists(DATA_PATH):
    st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: {DATA_PATH}")
    st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç DATA_PATH ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå app.py ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
    st.stop()

if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if prompt := st.chat_input("‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢... (‡πÄ‡∏ä‡πà‡∏ô '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏´‡∏Å‡∏£‡∏ì‡πå‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ï‡∏≤‡∏Å')"):
    
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    greetings = ["‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ", "‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö", "‡∏î‡∏µ‡∏Ñ‡πà‡∏∞", "‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢", "test", "‡πÄ‡∏ó‡∏™", "hi", "hello"]
    if any(g == prompt.lower() for g in greetings) or (any(g in prompt.lower() for g in greetings) and len(prompt) < 15):
        response_text = "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö! üëã ‡∏ú‡∏°‡∏Ñ‡∏∑‡∏≠ AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏©‡∏ï‡∏£ ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÅ‡∏•‡∏∞‡∏™‡∏´‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏±‡πâ‡∏á 17 ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î ‡∏ñ‡∏≤‡∏°‡∏ú‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö!"
        with st.chat_message("assistant"):
            st.markdown(response_text)
        st.session_state.messages.append({"role": "assistant", "content": response_text})
        st.stop()

    with st.chat_message("assistant"):
        start_time = time.time()
        
        # ================= LOGIC ‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ =================
        # 1. ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Å‡πà‡∏≠‡∏ô‡∏ß‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î(‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå)‡∏°‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        target_files, province_name = get_files_from_province_folder(DATA_PATH, prompt)
        
        # 2. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ logic ‡πÄ‡∏î‡∏¥‡∏° (‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ï‡∏≤‡∏° Keyword ‡∏´‡∏£‡∏∑‡∏≠ Backend ‡πÄ‡∏î‡∏¥‡∏°)
        # ‡∏´‡∏£‡∏∑‡∏≠‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÉ‡∏´‡πâ‡πÅ‡∏Å‡πâ else ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô
        if not target_files:
             target_files = backend.find_relevant_files(DATA_PATH, prompt)
             display_msg = f"üîç ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå (‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î)"
        else:
             display_msg = f"üìÇ ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î: **{province_name}**"
        # ======================================================

        if target_files:
            count = len(target_files)
            st.success(f"‚úÖ {display_msg} ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô {count} ‡πÑ‡∏ü‡∏•‡πå")
            
            timer_placeholder = st.empty()
            timer_placeholder.markdown("**‚è±Ô∏è ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏õ: 0.0 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ**")
            
            response_placeholder = st.empty()
            full_text = ""
            
            with st.status("üöÄ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•...", expanded=True) as status:
                st.write("üìÇ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå...")
                
                stream_generator = backend.ask_gemini_stream(
                    target_files, 
                    prompt, 
                    timer_placeholder=timer_placeholder, 
                    start_time=start_time
                )
                
                try:
                    first_chunk = next(stream_generator)
                    status.update(label="‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!", state="complete", expanded=False)
                    
                    full_text += first_chunk
                    response_placeholder.markdown(full_text + "‚ñå")
                    
                    elapsed = time.time() - start_time
                    timer_placeholder.markdown(f"**‚è±Ô∏è ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏õ: {elapsed:.1f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ** (‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå...)")

                    for chunk in stream_generator:
                        full_text += chunk
                        response_placeholder.markdown(full_text + "‚ñå")
                        elapsed = time.time() - start_time
                        timer_placeholder.markdown(f"**‚è±Ô∏è ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏õ: {elapsed:.1f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ** (‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå...)")
                    
                    response_placeholder.markdown(full_text)
                    
                    total_time = time.time() - start_time
                    timer_placeholder.markdown(f"**‚è±Ô∏è ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_time:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ**")
                    
                    st.session_state.messages.append({"role": "assistant", "content": full_text})

                except StopIteration:
                    status.update(label="‚ùå AI ‡πÑ‡∏°‡πà‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö", state="error")
                    st.error("‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: AI ‡πÑ‡∏°‡πà‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤")
                except Exception as e:
                    status.update(label="‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î", state="error")
                    st.error(f"Error: {e}")
        
        else:
            with st.spinner("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á..."):
                reply = backend.reply_general_chat(prompt)
            
            st.markdown(reply)
            st.session_state.messages.append({"role": "assistant", "content": reply})
