import streamlit as st
import os
import time
import backend

# =================‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö (Config)=================
# ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å st.secrets ‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ï‡∏£‡∏á‡πÜ
try:
    API_KEY = st.secrets["API_KEY"]
    DATA_PATH = st.secrets["DATA_PATH"]
except FileNotFoundError:
    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå secrets.toml ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå .streamlit/secrets.toml ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
    st.stop()
except KeyError as e:
    st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡πà‡∏≤ {e} ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå secrets.toml")
    st.stop()

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
st.set_page_config(page_title="Agricultural Data AI", page_icon="üåæ", layout="wide")

# ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Backend
try:
    backend.setup_api(API_KEY)
except Exception as e:
    st.error(f"‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")

# =================‡∏™‡πà‡∏ß‡∏ô‡πÇ‡∏´‡∏•‡∏î CSS=================
def load_css(file_name):
    with open(file_name, encoding="utf-8") as f:
        st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)

if os.path.exists("style.css"):
    load_css("style.css")

# =================‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• (UI)=================
st.markdown('<div class="main-title">üåæ ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏©‡∏ï‡∏£ 17 ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-title">AI Powered Data Analysis | Gemini 2.5 Flash Lite</div>', unsafe_allow_html=True)

# ‡πÄ‡∏ä‡πá‡∏Ñ Path ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
if not os.path.exists(DATA_PATH):
    st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: {DATA_PATH}")
    st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç DATA_PATH ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå app.py ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
    st.stop()

# ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÅ‡∏ä‡∏ó
if "messages" not in st.session_state:
    st.session_state.messages = []

# ‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÄ‡∏Å‡πà‡∏≤
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
if prompt := st.chat_input("‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢... (‡πÄ‡∏ä‡πà‡∏ô '‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏π‡∏Å‡∏Ç‡πâ‡∏≤‡∏ß‡∏£‡∏≤‡∏¢‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î')"):
    
    # 1. ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏¥‡∏î (‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡∏≥‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢)
    greetings = ["‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ", "‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö", "‡∏î‡∏µ‡∏Ñ‡πà‡∏∞", "‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢", "test", "‡πÄ‡∏ó‡∏™", "hi", "hello"]
    
    if any(g == prompt.lower() for g in greetings) or (any(g in prompt.lower() for g in greetings) and len(prompt) < 15):
        response_text = "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö! üëã ‡∏ú‡∏°‡∏Ñ‡∏∑‡∏≠ AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏©‡∏ï‡∏£ ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÅ‡∏•‡∏∞‡∏™‡∏´‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏±‡πâ‡∏á 17 ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î ‡∏ñ‡∏≤‡∏°‡∏ú‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö!"
        with st.chat_message("assistant"):
            st.markdown(response_text)
        st.session_state.messages.append({"role": "assistant", "content": response_text})
        st.stop()

    # 3. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
    with st.chat_message("assistant"):
        # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤
        start_time = time.time()
        
        target_files = backend.find_relevant_files(DATA_PATH, prompt)
        
        if target_files:
            # ‡πÄ‡∏à‡∏≠‡πÑ‡∏ü‡∏•‡πå -> ‡πÅ‡∏™‡∏î‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÑ‡∏ü‡∏•‡πå
            count = len(target_files)
            if count > 5:
                st.success(f"‚úÖ ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• **{count} ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î**")
            else:
                names = ", ".join([os.path.basename(f) for f in target_files])
                st.success(f"‚úÖ ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {count} ‡πÑ‡∏ü‡∏•‡πå: **{names}**")
            
            # --- ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏ß‡∏•‡∏≤ (Timer) ---
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ß‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡πÑ‡∏õ‡πÉ‡∏´‡πâ backend ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï
            timer_placeholder = st.empty()
            timer_placeholder.markdown("**‚è±Ô∏è ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏õ: 0.0 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ**")
            
            response_placeholder = st.empty()
            full_text = ""
            
            # --- ‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ (Status) ---
            with st.status("üöÄ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•...", expanded=True) as status:
                st.write("üìÇ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
                
                # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API ‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á timer_placeholder ‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢!
                # Backend ‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡πâ
                stream_generator = backend.ask_gemini_stream(
                    target_files, 
                    prompt, 
                    timer_placeholder=timer_placeholder, 
                    start_time=start_time
                )
                
                try:
                    # ‡∏£‡∏≠‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏£‡∏Å (Blocking Wait)
                    # ‡∏ä‡πà‡∏ß‡∏á‡∏ô‡∏µ‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏ô‡∏¥‡πà‡∏á‡πÑ‡∏õ‡∏™‡∏±‡∏Å‡∏û‡∏±‡∏Å‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤ AI ‡∏à‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡∏≠‡∏ö
                    first_chunk = next(stream_generator)
                    
                    # ‡∏û‡∏≠‡πÑ‡∏î‡πâ‡∏Ñ‡∏≥‡πÅ‡∏£‡∏Å -> ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ß‡πà‡∏≤‡πÄ‡∏™‡∏£‡πá‡∏à
                    status.update(label="‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!", state="complete", expanded=False)
                    
                    # ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡πÅ‡∏£‡∏Å
                    full_text += first_chunk
                    response_placeholder.markdown(full_text + "‚ñå")
                    
                    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
                    elapsed = time.time() - start_time
                    timer_placeholder.markdown(f"**‚è±Ô∏è ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏õ: {elapsed:.1f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ** (‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå...)")

                    # ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠
                    for chunk in stream_generator:
                        full_text += chunk
                        response_placeholder.markdown(full_text + "‚ñå")
                        
                        # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏ï‡∏•‡∏≠‡∏î‡∏Å‡∏≤‡∏£‡∏û‡∏¥‡∏°‡∏û‡πå
                        elapsed = time.time() - start_time
                        timer_placeholder.markdown(f"**‚è±Ô∏è ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏õ: {elapsed:.1f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ** (‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå...)")
                    
                    # ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô
                    response_placeholder.markdown(full_text)
                    
                    # ‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
                    total_time = time.time() - start_time
                    timer_placeholder.markdown(f"**‚è±Ô∏è ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_time:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ**")
                    
                    st.session_state.messages.append({"role": "assistant", "content": full_text})

                except StopIteration:
                    status.update(label="‚ùå AI ‡πÑ‡∏°‡πà‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö", state="error")
                    st.error("‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: AI ‡πÑ‡∏°‡πà‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤")
                except Exception as e:
                    status.update(label="‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î", state="error")
                    st.error(f"Error: {e}")
        
        else:
            with st.spinner("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ï‡∏£‡∏á‡πÜ... ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°..."):
                reply = backend.reply_general_chat(prompt)
            
            st.markdown(reply)
            st.session_state.messages.append({"role": "assistant", "content": reply})