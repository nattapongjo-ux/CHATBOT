import os
import time
import datetime
import google.generativeai as genai
import concurrent.futures
import streamlit as st

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•: ‡πÉ‡∏ä‡πâ Flash Lite ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
MODEL_NAME = 'gemini-2.5-flash-lite'

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Safety Settings
SAFETY_SETTINGS = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
]

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Generation Config
GENERATION_CONFIG = {
    "temperature": 0.3,
    "top_p": 0.8,
    "top_k": 40,
    "max_output_tokens": 8192,
}

def setup_api(api_key):
    """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API Key"""
    clean_key = api_key.strip()
    os.environ["GOOGLE_API_KEY"] = clean_key
    genai.configure(api_key=clean_key)

# ================= Smart Search (Logic ‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏≠‡∏≤‡πÑ‡∏ß‡πâ Fallback) =================
def find_relevant_files(root_folder, user_query):
    """
    ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡∏£‡∏≠‡∏á (‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°)
    """
    found_files_map = {} 
    query_normalized = user_query.lower()
    
    trigger_words = [
        "‡∏ó‡∏∏‡∏Å‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î", "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", "‡∏ó‡∏∏‡∏Å‡∏ó‡∏µ‡πà", "all provinces", "17 ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î", "‡∏ó‡∏±‡πà‡∏ß‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®", "‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°",
        "‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÑ‡∏´‡∏ô", "‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÉ‡∏î", "‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô", "‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö", "‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î", "‡∏ô‡πâ‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î", "‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö", "top", "rank",
        "‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏≠‡∏∞‡πÑ‡∏£", "‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á", "‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô‡∏ö‡πâ‡∏≤‡∏á", "‡∏Å‡∏µ‡πà‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î",
        "‡πÅ‡∏ï‡πà‡∏•‡∏∞", "‡∏£‡∏≤‡∏¢‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î", "‡πÅ‡∏¢‡∏Å‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î", "‡∏™‡∏£‡∏∏‡∏õ", "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô", "‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤", "‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ", "‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°", "‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥", "‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢"
    ]
    
    is_search_all_trigger = any(trigger in query_normalized for trigger in trigger_words)

    # ‡∏™‡πÅ‡∏Å‡∏ô‡∏´‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡∏Å‡∏£‡∏≠‡∏á
    try:
        mentioned_provinces = []
        with os.scandir(root_folder) as entries:
            for entry in entries:
                if entry.is_dir() and entry.name.lower() in query_normalized:
                    mentioned_provinces.append(entry.name.lower())
    except Exception:
        mentioned_provinces = []

    for dirpath, dirnames, filenames in os.walk(root_folder):
        folder_name = os.path.basename(dirpath).lower()
        should_check_folder = False

        if mentioned_provinces:
            if folder_name in mentioned_provinces: should_check_folder = True
        else:
            folder_match = (len(folder_name) > 1 and folder_name in query_normalized)
            should_check_folder = is_search_all_trigger or folder_match

        if should_check_folder:
            best_file = None
            max_score = 0
            
            # ‡πÄ‡∏ô‡πâ‡∏ô‡∏´‡∏≤ PDF ‡∏Å‡πà‡∏≠‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏ü‡∏•‡πå Excel/CSV
            target_exts = [".pdf", ".xlsx", ".csv", ".txt"]
            candidate_files = [f for f in filenames if any(f.lower().endswith(ext) for ext in target_exts)]
            
            for filename in candidate_files:
                file_name_no_ext = os.path.splitext(filename)[0].lower()
                # Logic ‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢
                current_score = 0
                if filename in query_normalized: current_score += 100
                if "‡∏™‡∏£‡∏∏‡∏õ" in filename or "report" in filename: current_score += 10
                
                # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á
                if folder_name in query_normalized: current_score += 50

                if current_score >= max_score:
                    max_score = current_score
                    best_file = os.path.join(dirpath, filename)
            
            if best_file:
                found_files_map[folder_name] = best_file

    return list(found_files_map.values())

# ================= Caching Upload =================
@st.cache_resource(show_spinner=False, ttl=3600)
def _upload_single_cached(path, last_modified_time):
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏Ñ‡πà‡∏≤ (Cache)
    """
    try:
        name = os.path.basename(path)
        uf = genai.upload_file(path=path, display_name=name)
        
        # ‡∏£‡∏≠ Processing
        retry_count = 0
        while uf.state.name == "PROCESSING":
            time.sleep(1)
            uf = genai.get_file(uf.name)
            retry_count += 1
            if retry_count > 60:
                break
                
        return uf if uf.state.name != "FAILED" else None
    except Exception as e:
        print(f"Error uploading {path}: {e}")
        return None

# ================= Main Gemini Function =================
def ask_gemini_stream(file_paths, question, timer_placeholder=None, start_time=None):
    """
    ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå -> ‡∏ï‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö Streaming
    ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö timer_placeholder ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
    """
    uploaded_files = []
    total = len(file_paths)
    
    # 1. Parallel Upload
    # ‡πÅ‡∏™‡∏î‡∏á Progress bar ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏≠‡∏ô‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î
    progress_text = f"üöÄ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {total} ‡πÑ‡∏ü‡∏•‡πå..."
    progress_bar = st.progress(0, text=progress_text)
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        future_map = {}
        for path in file_paths:
            try:
                mtime = os.path.getmtime(path)
                future = executor.submit(_upload_single_cached, path, mtime)
                future_map[future] = path
            except:
                pass

        done = 0
        for future in concurrent.futures.as_completed(future_map):
            res = future.result()
            if res: uploaded_files.append(res)
            done += 1
            
            # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï Progress Bar
            progress_bar.progress(done / total, text=f"‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß {done}/{total} ‡πÑ‡∏ü‡∏•‡πå (Cache Active ‚ö°)")
            
            # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ï‡∏±‡∏ß‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤ (‡∏ñ‡πâ‡∏≤‡∏™‡πà‡∏á‡∏°‡∏≤)
            if timer_placeholder and start_time:
                elapsed = time.time() - start_time
                timer_placeholder.markdown(f"**‚è±Ô∏è ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏õ: {elapsed:.1f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ** (‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå...)")
    
    progress_bar.empty() # ‡∏•‡∏ö Progress bar ‡∏≠‡∏≠‡∏Å‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏™‡∏£‡πá‡∏à

    if not uploaded_files:
        yield "‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö (Upload Failed)"
        return

    # 2. Prompt Construction
    model = genai.GenerativeModel(MODEL_NAME)
    payload = uploaded_files + [
        f"""
        Role: Agricultural Data Specialist for Thailand (17 Provinces).
        Task: Analyze the provided documents to answer the question accurately.
        
        Question: "{question}"
        
        Guidelines:
        - Answer based ONLY on the provided files.
        - If the user asks about a specific province (e.g., Tak), focus heavily on the files from that folder.
        - Use Thai language.
        - Convert Thai numerals (‡πë-‡πô) to Arabic (1-9).
        - If comparing data, use a Table or Bullet points.
        - If data is missing, state clearly "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£".
        """
    ]

    # 3. Streaming Response
    try:
        response = model.generate_content(
            payload, 
            stream=True, 
            safety_settings=SAFETY_SETTINGS,
            generation_config=GENERATION_CONFIG
        )
        for chunk in response:
            if chunk.text:
                yield chunk.text
    except Exception as e:
        yield f"‚ö†Ô∏è ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {str(e)}"

# ================= General Chat =================
def reply_general_chat(user_query):
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏∏‡∏¢‡πÄ‡∏•‡πà‡∏ô (‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠)
    """
    try:
        model = genai.GenerativeModel(MODEL_NAME)
        now = datetime.datetime.now().strftime("%H:%M ‡∏ô.")
        
        prompt = f"""
        ‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó: AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏©‡∏ï‡∏£ (‡∏™‡∏∏‡∏†‡∏≤‡∏û, ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á)
        
        ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á:
        1. ‡∏´‡∏≤‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢/‡∏ñ‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤: ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏™‡∏∏‡∏†‡∏≤‡∏û (‡πÄ‡∏ß‡∏•‡∏≤: {now})
        2. ‡∏´‡∏≤‡∏Å‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç/‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥: ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ "‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö Drive ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö"
            
        User: {user_query}
        """
        
        response = model.generate_content(
            prompt, 
            safety_settings=SAFETY_SETTINGS,
            generation_config=GENERATION_CONFIG
        )
        return response.text
            
    except Exception as e:
        return f"‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡∏£‡∏∞‡∏ö‡∏ö AI ‡∏Ç‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏á‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß: {str(e)}"
